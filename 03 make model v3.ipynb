{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b08d3d00-12e2-4c13-bbbd-1a2524557e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import keras_nlp\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow.data as tf_data\n",
    "import tensorflow.strings as tf_strings\n",
    "import tensorflow.keras.optimizers.schedules as schedules\n",
    "from keras.layers import LeakyReLU\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46d98ccc-0173-4b8d-9c78-1d18ecd86ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Parameters\n",
    "BATCH_SIZE = 16\n",
    "MIN_STRING_LEN = 32  # Strings shorter than this will be discarded\n",
    "SEQ_LEN = 512  # Length of training sequences, in tokens\n",
    "\n",
    "# Model\n",
    "EMBED_DIM = 1024\n",
    "FEED_FORWARD_DIM = 1024\n",
    "NUM_HEADS = 16\n",
    "NUM_LAYERS = 20\n",
    "VOCAB_SIZE = 50000  # Limits parameters in model.\n",
    "\n",
    "# Training\n",
    "EPOCHS = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2d0706a-441f-4058-9942-f4f5f3048156",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_ds = (\n",
    "    #tf_data.TextLineDataset('./dataset/wikitext-103/WikiQA-train.txt')\n",
    "    tf_data.TextLineDataset('./dataset/squadtrain-v2.0.txt')\n",
    "#    tf_data.TextLineDataset('./dataset/wikitext-103/wiki.train300klines.tokens')\n",
    "    .filter(lambda x: tf_strings.length(x) > MIN_STRING_LEN)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .shuffle(buffer_size=256)\n",
    ")\n",
    "\n",
    "raw_val_ds = (\n",
    "    tf_data.TextLineDataset('./dataset/WikiQA-dev.txt')\n",
    "    .filter(lambda x: tf_strings.length(x) > MIN_STRING_LEN)\n",
    "    .batch(BATCH_SIZE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b44fad0b-eeed-433d-9981-ca32870e99a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./models/wikitext103_tokenizer50k.pkl', 'rb') as saved_tokenizer:\n",
    "    tokenizer = pickle.load(saved_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b363001-1241-4ab3-96fe-3256580e476a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packer adds a start token\n",
    "start_packer = keras_nlp.layers.StartEndPacker(\n",
    "    sequence_length=SEQ_LEN,\n",
    "    start_value=tokenizer.token_to_id(\"[BOS]\"),\n",
    ")\n",
    "\n",
    "\n",
    "def preprocess(inputs):\n",
    "    outputs = tokenizer(inputs)\n",
    "    features = start_packer(outputs)\n",
    "    labels = outputs\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "# Tokenize and split into train and label sequences.\n",
    "train_ds = raw_train_ds.map(preprocess, num_parallel_calls=tf_data.AUTOTUNE).prefetch(\n",
    "    tf_data.AUTOTUNE\n",
    ")\n",
    "val_ds = raw_val_ds.map(preprocess, num_parallel_calls=tf_data.AUTOTUNE).prefetch(\n",
    "    tf_data.AUTOTUNE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6960f0-964e-43ec-a6d1-2637a84828df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a44d4c9-b615-4d74-b5b9-38176610ac6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.layers.Input(shape=(None,), dtype=\"int32\")\n",
    "# Embedding.\n",
    "embedding_layer = keras_nlp.layers.TokenAndPositionEmbedding(\n",
    "    vocabulary_size=VOCAB_SIZE,\n",
    "    sequence_length=SEQ_LEN,\n",
    "    embedding_dim=EMBED_DIM,\n",
    "    mask_zero=True,\n",
    ")\n",
    "x = embedding_layer(inputs)\n",
    "# Transformer decoders.\n",
    "for _ in range(NUM_LAYERS):\n",
    "    decoder_layer = keras_nlp.layers.TransformerDecoder(\n",
    "        num_heads=NUM_HEADS,\n",
    "        intermediate_dim=FEED_FORWARD_DIM,\n",
    "        activation=LeakyReLU(0.1),\n",
    "    )\n",
    "    x = decoder_layer(x)  # Giving one argument only skips cross-attention.\n",
    "# Output.\n",
    "outputs = keras.layers.Dense(VOCAB_SIZE)(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "#learningrate = schedules.PolynomialDecay(5e-5, decay_steps=50000, end_learning_rate=2e-5)\n",
    "opt = keras.optimizers.Adam(learning_rate=5e-5)\n",
    "perplexity = keras_nlp.metrics.Perplexity(from_logits=True, mask_token_id=0)\n",
    "model.compile(optimizer=opt, loss=loss_fn, metrics=[perplexity])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a11d54a5-caa1-4d16-a9df-aabe87333edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " token_and_position_embeddin  (None, None, 1024)       51724288  \n",
      " g (TokenAndPositionEmbeddin                                     \n",
      " g)                                                              \n",
      "                                                                 \n",
      " transformer_decoder (Transf  (None, None, 1024)       6301696   \n",
      " ormerDecoder)                                                   \n",
      "                                                                 \n",
      " transformer_decoder_1 (Tran  (None, None, 1024)       6301696   \n",
      " sformerDecoder)                                                 \n",
      "                                                                 \n",
      " transformer_decoder_2 (Tran  (None, None, 1024)       6301696   \n",
      " sformerDecoder)                                                 \n",
      "                                                                 \n",
      " transformer_decoder_3 (Tran  (None, None, 1024)       6301696   \n",
      " sformerDecoder)                                                 \n",
      "                                                                 \n",
      " transformer_decoder_4 (Tran  (None, None, 1024)       6301696   \n",
      " sformerDecoder)                                                 \n",
      "                                                                 \n",
      " transformer_decoder_5 (Tran  (None, None, 1024)       6301696   \n",
      " sformerDecoder)                                                 \n",
      "                                                                 \n",
      " transformer_decoder_6 (Tran  (None, None, 1024)       6301696   \n",
      " sformerDecoder)                                                 \n",
      "                                                                 \n",
      " transformer_decoder_7 (Tran  (None, None, 1024)       6301696   \n",
      " sformerDecoder)                                                 \n",
      "                                                                 \n",
      " transformer_decoder_8 (Tran  (None, None, 1024)       6301696   \n",
      " sformerDecoder)                                                 \n",
      "                                                                 \n",
      " transformer_decoder_9 (Tran  (None, None, 1024)       6301696   \n",
      " sformerDecoder)                                                 \n",
      "                                                                 \n",
      " transformer_decoder_10 (Tra  (None, None, 1024)       6301696   \n",
      " nsformerDecoder)                                                \n",
      "                                                                 \n",
      " transformer_decoder_11 (Tra  (None, None, 1024)       6301696   \n",
      " nsformerDecoder)                                                \n",
      "                                                                 \n",
      " transformer_decoder_12 (Tra  (None, None, 1024)       6301696   \n",
      " nsformerDecoder)                                                \n",
      "                                                                 \n",
      " transformer_decoder_13 (Tra  (None, None, 1024)       6301696   \n",
      " nsformerDecoder)                                                \n",
      "                                                                 \n",
      " transformer_decoder_14 (Tra  (None, None, 1024)       6301696   \n",
      " nsformerDecoder)                                                \n",
      "                                                                 \n",
      " transformer_decoder_15 (Tra  (None, None, 1024)       6301696   \n",
      " nsformerDecoder)                                                \n",
      "                                                                 \n",
      " transformer_decoder_16 (Tra  (None, None, 1024)       6301696   \n",
      " nsformerDecoder)                                                \n",
      "                                                                 \n",
      " transformer_decoder_17 (Tra  (None, None, 1024)       6301696   \n",
      " nsformerDecoder)                                                \n",
      "                                                                 \n",
      " transformer_decoder_18 (Tra  (None, None, 1024)       6301696   \n",
      " nsformerDecoder)                                                \n",
      "                                                                 \n",
      " transformer_decoder_19 (Tra  (None, None, 1024)       6301696   \n",
      " nsformerDecoder)                                                \n",
      "                                                                 \n",
      " dense (Dense)               (None, None, 50000)       51250000  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 229,008,208\n",
      "Trainable params: 229,008,208\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('./checkpoints/Model_240M_50kvocab_10EpochSquadfinetune.krs')\n",
    "keras.backend.set_value(model.optimizer.learning_rate, 1e-6)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "488348b1-0b13-4d29-85eb-3ce301f0ac73",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5399/5399 [==============================] - 3951s 729ms/step - loss: 0.1540 - perplexity: 125.3804 - val_loss: 0.3520 - val_perplexity: 145.7462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x265e0617880>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 733,728 / batch size = num steps\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76379084-2135-4a6b-9e06-7349a3072d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as token_embedding_layer_call_fn, token_embedding_layer_call_and_return_conditional_losses, position_embedding_layer_call_fn, position_embedding_layer_call_and_return_conditional_losses, leaky_re_lu_layer_call_fn while saving (showing 5 of 564). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./checkpoints/Model_240M_50kvocab_10EpochSquadfinetune.krs\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./checkpoints/Model_240M_50kvocab_10EpochSquadfinetune.krs\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"./checkpoints/Model_240M_50kvocab_10EpochSquadfinetune.krs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81a8175a-39a3-44d7-b7dc-9a0dccc84afe",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "5399/5399 [==============================] - 3928s 727ms/step - loss: 0.1442 - perplexity: 92.7376 - val_loss: 0.3511 - val_perplexity: 145.9524\n",
      "Epoch 2/15\n",
      "5399/5399 [==============================] - 3931s 728ms/step - loss: 0.1403 - perplexity: 82.1831 - val_loss: 0.3496 - val_perplexity: 143.5085\n",
      "Epoch 3/15\n",
      "5399/5399 [==============================] - 3947s 731ms/step - loss: 0.1375 - perplexity: 75.4363 - val_loss: 0.3495 - val_perplexity: 144.3310\n",
      "Epoch 4/15\n",
      "5399/5399 [==============================] - 3945s 731ms/step - loss: 0.1353 - perplexity: 70.4152 - val_loss: 0.3495 - val_perplexity: 144.2572\n",
      "Epoch 5/15\n",
      "5399/5399 [==============================] - 3946s 731ms/step - loss: 0.1334 - perplexity: 66.4242 - val_loss: 0.3509 - val_perplexity: 147.4005\n",
      "Epoch 6/15\n",
      "5399/5399 [==============================] - 3942s 730ms/step - loss: 0.1318 - perplexity: 63.0547 - val_loss: 0.3499 - val_perplexity: 145.6506\n",
      "Epoch 7/15\n",
      "4120/5399 [=====================>........] - ETA: 15:22 - loss: 0.1293 - perplexity: 60.0753"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 733,728 / batch size = num steps\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 733,728 / batch size = num steps\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7ba6d00-9388-49ad-9246-8280c2a3657b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as token_embedding_layer_call_fn, token_embedding_layer_call_and_return_conditional_losses, position_embedding_layer_call_fn, position_embedding_layer_call_and_return_conditional_losses, leaky_re_lu_layer_call_fn while saving (showing 5 of 564). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./checkpoints/Model_240M_50kvocab_30ksSquadfinetune.krs\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./checkpoints/Model_240M_50kvocab_30ksSquadfinetune.krs\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"./checkpoints/Model_240M_50kvocab_30ksSquadfinetune.krs\")\n",
    "#loaded_model = keras.saving.load_model(\"model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fcf9e4b6-8178-45cb-aa2e-da26f931f703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a0027b4-b7cd-4aa6-badb-22798ae442a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 512), dtype=int32, numpy=\n",
       "array([[   2, 1146, 3178,  984, 1097, 1255,  983, 3703, 1251,   33,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0]])>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_tokens = start_packer(tokenizer([\"What genre of music do the beatles play?\"]))\n",
    "prompt_length = np.sum(prompt_tokens.numpy() != 0)\n",
    "prompt_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b26ccfd0-b000-4b63-8975-887764c45330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "NUM_TOKENS_TO_GENERATE = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06beb7ee-e433-4a6a-9bb8-c4e8569b2de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next(prompt, cache, index):\n",
    "    logits = model(prompt)[:, index - 1, :]\n",
    "    # Ignore hidden states for now; only needed for contrastive search.\n",
    "    hidden_states = None\n",
    "    return logits, hidden_states, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ca4d4805-55fa-4641-9a82-8fd4891f0a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-P search generated text: \n",
      "what genre of music do the beatles play ? rock and roll\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampler = keras_nlp.samplers.TopPSampler(p=0.5)\n",
    "output_tokens = sampler(\n",
    "    next=next,\n",
    "    prompt=prompt_tokens,\n",
    "    index=prompt_length,\n",
    ")\n",
    "txt = tokenizer.detokenize(output_tokens)\n",
    "output_txt = str(txt.numpy()[0]).split(\"b'[BOS] \")[-1].split(' [PAD]')[0]\n",
    "print(f\"Top-P search generated text: \\n{output_txt}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84ef7ad2-ab2e-4074-984d-129434eef9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as token_embedding_layer_call_fn, token_embedding_layer_call_and_return_conditional_losses, position_embedding_layer_call_fn, position_embedding_layer_call_and_return_conditional_losses, leaky_re_lu_layer_call_fn while saving (showing 5 of 564). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./checkpoints/Model_240M_50kvocab_10EpochWikiQAfinetune.krs\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./checkpoints/Model_240M_50kvocab_10EpochWikiQAfinetune.krs\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"./checkpoints/Model_240M_50kvocab_10EpochWikiQAfinetune.krs\")\n",
    "#loaded_model = keras.saving.load_model(\"model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4007f84b-3fbe-43f4-a04d-ccbc55348794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([b'[BOS] what is the capital city of america ? northwestern [PAD]rt [PAD]n [PAD]d [PAD]nza [PAD] [PAD]n [PAD]n [PAD]nn [PAD]n [PAD]n [PAD]nni [PAD] [PAD]s [PAD]l [PAD]ll - d - nw [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'], shape=(1,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "58bae64f-8ade-408b-9068-92e55969bc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what are the three rock types ?'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e713a27f-fcb4-42a1-aa45-e6060b9565a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 512), dtype=int32, numpy=\n",
       "array([[    2,  1146,  1014,   983,  1046,  1420,  3009,    33,  4629,\n",
       "         1420,    14,  1420,    14,   985,  1801,  1097,     0,  1420,\n",
       "            0,  1020,     0,  1020,     0,   985,  3604,  1294,     0,\n",
       "         1020,     0,  1420,   985,  1801,     0,     0,     0,  1020,\n",
       "            0,  1520,   985, 13085,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,  1020,     0,  1420,    16,     0,\n",
       "          985,  1011,  1897,   989,   983,  2971,  1097,  1840,     0,\n",
       "          985,  1840,     0,     0,     9,    59,  8138,   984,  2852,\n",
       "         1097,  1840,     0,  1020,     0,     9,    14,   995,  1049,\n",
       "           41,  2655,  2832,   986,  3193,     0,  1240,     0,  1420,\n",
       "         1097,     0,  1020,   986,   983,  2380,  1152,    16,     0,\n",
       "            9, 14808,   985,     9, 14808,     0,  3396, 15896, 11048,\n",
       "            0,  1020,     0,  1420,     0,  1020,    14,  4013,   985,\n",
       "         1317,  1097,     0,  1020,    14,     9,     9, 14808,    14,\n",
       "            9,   985,     9, 14808,     9,  1014,  4219,   984,  2971,\n",
       "         1420,  3552,     0,   985,  1146,  1033,  1458,   984,  1097,\n",
       "         3552,     0,  1190, 12023,   987,  1299,  1554,   993,   983,\n",
       "         3178,    33,  2084,  1420,     0,     0,  1020,     0,  3036,\n",
       "         3333,  6517,     0,     0,   985,  2084,  1420,     0,     0,\n",
       "            0,     0,  1020,     0,   985,  4013,  3037,     0,   985,\n",
       "         1011,  4237,     0,   985,  1979,     0,     9,  1284,  3552,\n",
       "            0,   985,  8457,     0,  1023,  3037,     0,   985,  1284,\n",
       "         3552,     0,    16,     0,   985,    14,     9, 14808,  1420,\n",
       "         1097,   995,  1016,  1109,   991,  1420,  1097,    16,     0,\n",
       "         1420,   985,  4206,  1097,    14,  1420,   985,  1317,  1097,\n",
       "           14,   985,  1420,  1097,  1014,  1016,  1554,  1097,  3037,\n",
       "           16,     0,  1020,   985,  3037,  1022,  1026,  2396,   994,\n",
       "         1420,  1097,    14,  1420,   985,  4206,  1097,    14,   985,\n",
       "         1964,  1097,  1027,  1026,  2396,   994,  1420,  1097,    16,\n",
       "            0,  1187,  1097,   995,    41,  1186,  1897,   989,  1420,\n",
       "         1097,    14,  1086,  1317,  1420,    14,  1317,  1420,    14,\n",
       "         1317,  1420,    14,  1317,  1420,    14,   985,  1964,  1097,\n",
       "           16,     0,  1420,   985,  1317,  1097,  1027,  2396,  1077,\n",
       "          984,   983,  6501,   984,  1317,  1097,   985,  2337,  1097,\n",
       "           14,  1086,  1420,    14,  1317,    14,  1317,    14,  1317,\n",
       "           14,  1317,    14,  1317,    14,  1317,    14,  1317,   985,\n",
       "         1317,  1097,    16,     0,   985,  1027,  1026,  2396,   994,\n",
       "         1317,  1097,   985,  1317,  1097,    14,  1420,   985,  1317,\n",
       "         1097,    16,     0,  1317,  1097,   995,  1016,  1992,   993,\n",
       "         1317,  1097,    14,  1317,  1097,    14,  1317,  1097,    14,\n",
       "         1317,  1097,    14,  1317,  1097,    14,  1317,  1097,    14,\n",
       "         1317,  1097,    14,  1317,  1097,    14,  1317,  1097,    14,\n",
       "         1317,  1097,    14,  1317,  1097,    14,  1317,  1097,    14,\n",
       "         1317,  1097,    14,  1317,  1097,    14,  1317,  1097,    14,\n",
       "         1317,  1097,    14,  1317,  1097,    14,  1317,  1097,    14,\n",
       "         1317,  1097,    14,  1317,  1097,    14,  1317,  1097,    14,\n",
       "         1317,  1097,    14,  1317,  1097,    14,  1317,  1097,    14,\n",
       "         1317,  1097,    14,  1317,  1097,    14,  1317,  1097,    14,\n",
       "         1317,  1097,    14,  1317,  1097,    14,  1317,  1097,    14,\n",
       "         1317,  1097,    14,  1317,  1097,    14,  1317,  1097,    14,\n",
       "         1317,  1097,    14,  1317,  1097,    14,  1317,  1097,    14,\n",
       "         1317,  1097,    14,  1317,  1097,    14,  1317,  1097,    14,\n",
       "         1317,  1097,    14,  1317,  1097,    14,  1317,  1097,    14,\n",
       "         1317,  1097,    14,  1317,  1097,    14,  1317,  1097,    14,\n",
       "         1317,  1097,    14,  1317,  1097,    14,  1317,  1097,    14,\n",
       "         1317,  1097,    14,  1317,  1097,    14,  1317,  1097,    14,\n",
       "         1317,  1097,    14,  1317,  1097,    14,  1317,   985]])>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10644c06-c893-47fa-a394-2b182e9d1a04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
